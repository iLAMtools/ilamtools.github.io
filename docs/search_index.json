[["index.html", "iLAM: imaging Locomotor Activity Monitor 1 Description", " iLAM: imaging Locomotor Activity Monitor 2024-05-04 1 Description Historically, most insect chronoecological research has used direct observations, cameras, and/or infrared beam-based monitors to quantify movement across timed intervals. Although many systems are cheaper than the traditional infrared locomotor activity monitors (e.g., DAM/LAM), these options can remain complicated to build, computationally intensive to setup/process, and/or unable to accommodate large-bodied insects (i.e., not Drosophila). To fill this gap, we developed the affordable, imaging Locomotor Activity Monitor (iLAM) for activity quantification. The iLAM utilizes a Raspberry Pi Zero W computer and night-vision camera inside a flight cage to regularly photograph a population of insects at user-defined intervals. Customizable, modular R-scripts process consecutive images with imager and output a file containing the number, size, location, and timing of all identified movements. Movement data can be converted into DAM format or directly analyzed within the Rethomics framework. Out-of-the-box functions can be downloaded and installed from our iLAMtools R package by: library(devtools) devtools::install_github(&quot;daytonjn/iLAMtools&quot;, force=TRUE) library(iLAMtools) Figure 1.1: iLAM Workflow Figure 1.2: Representative firefly movements identified by iLAM system This resource provides detailed instructions for (1) iLAM construction, (2) Raspberry Pi setup, (3) Image analysis in R, (4) conversion of iLAM output to DAM format in R, and (5) Sample results using Rethomics. "],["flight-cage-construction.html", "2 Flight Cage Construction", " 2 Flight Cage Construction The paired iLAM flight cages described in our original publication used the following materials: Table 2.1: iLAM materials Item Function Units/Setup Black mosquito head net mesh big size, 6.69” x 3.94” x 1.38” Cage 2 Wooden embroidery hoop, 14” Cage 4 Wooden embroidery hoop, 8” Cage 2 Hardwood plywood, 1/2” x 4’ x 8’ Structure 0.25 Steel threaded rod, 3/8”-16 x 2’ Structure 6 Steel hex nut, 3/8”-16 Structure 36 Steel washer, 3/8” Structure 36 No See Um fiberglass mesh screening, 36” x 25’ Cover 0.04 Falcon tube, 50mL Water 2 Braided cotton roll, 4” Water 2 Sponge Water 2 Raspberry Pi Zero W Computer 2 Raspberry Pi Zero W Case Case 2 Raspberry Pi Zero W camera module night vision w/ 3.6mm, 2pcs IR sensor LED light Camera 2 SanDisk Ultra 32GB microSD card Memory 2 Micro USB charging cord/block Power 2 All materials were purchased from local hardware stores, art supply chains, Raspberry Pi suppliers, and Amazon The three cage levels were made with the following cuts: Top: 31 1/2” x 10 1/2” Two Circles: 13 3/8” diameter (&lt;14” hoop) Bottom: 31 1/2” x 10 1/2” Two Circles: 7 1/2” diameter (&lt;8” hoop) Hole for camera ribbon Base: 31 1/2” x 10 1/2” Figure 2.1: iLAM flight cage: front view Figure 2.2: iLAM flight cage: top-down view Tips: To increase the lifespan of experimental insects and the experiment’s recording duration, add cups with moist sponges and a falcon tube with a cotton roll and water (held by Velcro) To prevent escape by small experimental insects (e.g., Photinus species), add duct-tape around the camera ribbon cable hole and camera Depending on the color that the study insect appears under infrared light (i.e., white vs. black appearance), change the background of the lid to maximize contrast To minimize differences in the photographed light environment throughout light:dark/dark:light transitions, we now: Cover the Raspberry Pi’s light sensors with black duct tape or plastic; this “tricks” the Pi to keep it’s infrared lights on 24/7 Cover the Raspberry Pi’s camera lens with a longpass filter that only permits infrared light to the camera Optional add-ons: Realtime clock (RTC) module "],["raspberry-pi-zero-wcamera-setup.html", "3 Raspberry Pi Zero w/Camera Setup", " 3 Raspberry Pi Zero w/Camera Setup Steps to program the Raspberry Pi Zero computers to capture and store images: 1. Obtain necessary cables/connectors: USB 2.0 to microSD card reader (to image SD card on a PC) USB 2.0 microUSB male to USB female adapter (to connect keyboard with Pi) Keyboard with USB 2.0 wire Micro HDMI male to HDMI female adapter &amp; HDMI cable (to connect monitor with Pi) or micro HDMI to HDMI cable 2. Install operating system: Figure 3.1: Raspberry Pi Imager Use microSD card reader to mount SD card onto a PC Download and open Raspberry Pi Imager Choose OS → Raspberry Pi OS (Other) → Raspberry Pi OS Lite (32-bit) Choose Storage → Drive referring to microSD card Optional: Gears → Set hostname (name of the pi on your wifi network that you ssh [pi_name]@[IP Address] into) Enable ssh Set username and password (user login information to access the pi) Set locale settings (e.g., America/New York &amp; us) Write Disconnect and insert formatted microSD card into Pi Connect Pi to keyboard, monitor, and power source Once connected to power, Pi automatically turns on 2. Login with default or already specified login information: raspberrypi login: pi password: raspberry 3. Configure Pi settings: sudo raspi-config Use arrow keys and Enter to navigate 1 → S1 Connect to wifi SSID: wifi network name Passphrase: wifi password 1 → S3 change pi password 1 → S4 change pi name (not login) 3 → I1 enable camera attachment 3 → I2 enable remote access (ssh) 5 → L2 set timezone Finish (type y when asked if you want to reboot) 4. Add static IP address for remote access: https://raspberrypi-guide.github.io/networking/set-up-static-ip-address 5. Continue programming directly or remotely access the Pi through terminal from another PC: ssh login_name@[IP address] password: 6. Make a folder/directory named ‘still’ to hold images: mkdir still_[xxx] Note: [xxx] refers to the login name of the Raspberry Pi associated with the iLAM 7. Make a directory named script to hold scripts: mkdir script_[xxx] 8. Write a script using a text-editor (e.g., nano) named still_[xxx].sh: sudo nano ./script_[xxx]/still_[xxx].sh and write the following text: #!/bin/bash DATE=$(date +&quot;%m%d.%H%M&quot;) sudo raspistill -o /home/$USER/still_$USER/$USER.$DATE.jpg This script will take images and save them along w/ metadata into the still_$USER directory: (Line 1) necessary for any bash file with instructions (Line 2) sets the format for the date and time in the file name (Line 3) command for pi to take a photo and store it with specified file name/location. Hit control^X to exit (type y when asked if you want to save) 9. To automatically upload/copy images into a remote directory, you may (A) use scp to upload each image after it’s taken, or (b) mount a remote directory and then copy each image. ssh-keygen and ENTER to generate a new SSH key to enable a custom script to automatically upload images without requiring a password input ssh-copy-id -i ~/.ssh/id_rsa [remote_PC_hostname]@[remote_PC IP address] Input password for remote_PC Option A: Add the following line to the end of still_[xxx].sh: scp /home/$USER/still_$USER/$USER.$DATE.jpg [remote_PC_hostname]@[remote_PC IP address]:[directory that you want images saved into]/ Option B: Add the following lines to the end of still_[xxx].sh: sleep 10 scp /home/$USER/still_$USER/$USER.$DATE.jpg /home/$USER/mount_$USER/ 10. Schedule the imaging script to run periodically with crontab: Access the crontab file sudo crontab -e Select the first option to edit the crontab in nano Copy the following to the bottom of the file: */2 * * * * sh /home/$USER/script_$USER/still_$USER.sh 2&gt;&amp;1 This tells the pi to execute the still.sh file every 2 minutes (the order is minute, hour, day of month, month, day of week). When setting up a new crontab, always run it past crontab.guru! control^X to exit (type y when asked if you want to save) 11. Access Raspberry Pi image files on your PC: Even if your iLAM/Pi is programmed to upload files to a remote computer over Wifi, at the end of every experiment, we recommend verifying that all images were properly uploaded/transferred. To remotely download images, you may: Option A: Download images via Command line Log in to the Linux/Powershell on your laptop scp pi@[IP address]:~/still_[xxx]/*.jpg ~/[target directory]` Option B: Download images via a free file transfer program (FTP) like FileZilla Open FileZilla: In Site Manager, choose New site Protocol: SFTP - SSH File Transfer Protocol Host: [IP Address of Raspberry Pi] Logon Type: Normal User: [Pi login name] Password: [Pi login password] Connect Trouble-shooting -raspistill will not take a picture and returns** *failed to open vchiq instance: Verify that the camera is connected and the ribbon cable is not damaged: vcgencmd get_camera Determine if the camera or the still_[xxx].sh script is the issue: raspistill -o /home/$USER/test.jpg Modify permissions of the camera: sudo chmod777 /dev/vchiq A Linux reader is required to read the Raspian imaged SD card, when plugged into a Windows PC. Linux Reader is a free option. Instructions can be found here. Tips: Useful Linux commands: * wildcard (e.g. *.jpg == all jpeg files) control^A bring cursor to beginning of line control^E bring cursor to end of line control^C kill process clear clear all previous text from terminal ls list all contents in current folder cd directory_path change to named folder cd ~ go to home directory cd .. go up one folder level cd - go back to last folder mkdir dir_name create EMPTY folder (directory) rmdir dir_name remove EMPTY folder rm file_name remove a file rm -f file_name remove a file without asking for permission rm -r dir_name recursively remove all files from folder rm -rf dir_name forcefully remove all files from folder ren name_1 name_2 rename something to something else cp file_1 file_2 copy file_1 to file_2, creates duplicate. note: if file_2 exists will overwrite (NO warning) cp -r dir_1 dir_2 copy folder and its contents nano file_name make named file and open text editor sudo reboot reboot pi sudo shutdown now safely shutdown pi (reboots when plugged in again) "],["post-process-image-segmentation.html", "4 Post-Process Image Segmentation", " 4 Post-Process Image Segmentation Below is a walk-through for the post-process image segmentation (i.e., blob identification) of iLAM images to identify movements 1. Organize your file directory structure in a logical, hierarchical structure ~/iLAM/exp_a/ contains images, metadata, and analysis scripts specific to Experiment A Experiment A’s images from ilam_01 and ilam_02 are saved in ~/iLAM/exp_a/ilam_01/ and ~/iLAM/exp_a/ilam_02/, respectively .CSV output containing the size, location, and timing of all blobs/movements for each iLAM cages for Experiment A (i.e., ilam_01 and ilam_02):~/iLAM/exp_a/iLAM_exp_a.txt/, with corresponding metadata: ~/iLAM/exp_a/metadata_exp_a.csv/ ## Warning: package &#39;data.tree&#39; was built under R version 4.3.3 ## levelName ## 1 iLAM ## 2 ¦--exp_a ## 3 ¦ ¦--ilam01 ## 4 ¦ ¦ ¦--ilam01.0707.2058.jpg ## 5 ¦ ¦ °--ilam01.0707.2100.jpg ## 6 ¦ ¦--ilam02 ## 7 ¦ ¦ ¦--ilam02.0707.2058.jpg ## 8 ¦ ¦ °--ilam02.0707.2100.jpg ## 9 ¦ ¦--scripts ## 10 ¦ ¦ ¦--analyze_experiment.R ## 11 ¦ ¦ ¦--exp_a_ilam01.R ## 12 ¦ ¦ ¦--exp_a_ilam02.R ## 13 ¦ ¦ ¦--run_exp_a_ilam01.sh ## 14 ¦ ¦ °--run_exp_a_ilam02.sh ## 15 ¦ ¦--metadata_exp_a.csv ## 16 ¦ °--iLAM_exp_a.txt ## 17 ¦--exp_b ## 18 ¦ ¦--ilam01 ## 19 ¦ ¦--ilam02 ## 20 ¦ °--scripts ## 21 °--scripts ## 22 ¦--add_columns_to_42.R ## 23 ¦--find_movements.R ## 24 ¦--find_threshold.R ## 25 ¦--make_dam_file.R ## 26 ¦--make_gif.R ## 27 ¦--parse_movements.R ## 28 °--plot_movements.R 2. Install iLAMtools from GitHub library(devtools) devtools::install_github(&quot;daytonjn/iLAMtools&quot;, force=TRUE) library(iLAMtools) Alternatively, you can download iLAM functions from this zip folder: iLAM wrapper functions and reference them with ‘source()’. To verify installation, a zip folder containing a set of sample images and test script can be downloaded here (198MB): iLAM_test folder 2. Perform image segmentation to identify movements across images taken by each iLAM (exp_a_ilam01.R, exp_a_ilam02.R, etc.) Figure 4.1: Image segmentation workflow Load required packages and iLAM functions setwd(&quot;/~/iLAM/exp_a/&quot;) library(iLAMtools) Update and tailor values for every cage and/or experiment; these values are recorded to metadata output and used as input settings for the find_movements() iLAM wrapper function: Cage-Specific: Integer coordinates for image cropping (x_left, x_right, y_bot, y_top) Experiment-Specific: n_thr: Numeric threshold percentile; higher values indicate a more stringent filtering. e.g., at n_thr=0.999, only the darkest pixel differences &gt;99.9% are retained for blob identification (default: n_thr = 0.996) Note: For moths (O. nubilalis, H. zea, S. frugiperda), we use: n_thr=0.999 Note: For beetles (Photinus species, H. axyridus), we use: n_thr=0.999 n_cln: Integer value to clean up pixels: e.g., at n_cln = 5, this first “shrinks” to remove all isolated blobs smaller than 5 pixels, and then “grows” remaining blobs by 5*n_grw pixels to aggregate nearby blobs with each other. (default: n_cln = 5, n_grw = 1.5) Note: For moths (O. nubilalis, H. zea, S. frugiperda), we use: n_cln=10, n_grw=1.5 Note: For beetles (Photinus species, H. axyridus), we use: n_cln=10, n_grw=1.5 genus: Character string for study organism species: Character string for study organism color: Character string to indicate whether the study organism appears “white” or “black” on the background Note: For moths (O. nubilalis, H. zea, S. frugiperda), we use: “white” Note: For beetles (Photinus species), we use: “black” For more information on threshold, clean, blur, etc., see imager documentation for more details. pi_sub_folder &lt;- &quot;ilam01&quot; sex &lt;- &quot;male&quot; #cage/project-specific #Crop-settings x_left &lt;- 425 #cage-specific, depending on camera arrangement x_right &lt;- 2225 #cage-specific, depending on camera arrangement y_bot &lt;- 100 #cage-specific, depending on camera arrangement y_top &lt;- 1700 #cage-specific, depending on camera arrangement #change following values for every experiment out_file_name = &quot;iLAM_exp_a&quot; #project-specific n_thr = 0.999 #species-specific, depending on IR reflectance/contrast with background n_cln = 10 #species-specific, depending on IR reflectance n_max = 75000 #species-specific, pixel differences above this value will be considered as noise start_photophase = 5 #project-specific, time that lights turn on end_photophase = 21 #project-specific, time that dark starts genus = &quot;photinus&quot; #project-specific species = &quot;marginellus&quot; #project-specific animal = &quot;black&quot; #project-specific, during the night, does the animal appear &quot;white&quot; on a dark background or &quot;black&quot; on a light background? This is VERY important (!) because it determines whether &quot;movements&quot; identify insects whom left vs. arrived between frames Create a vector of .jpg image file names to be analyzed file_names &lt;- list.files(pi_sub_folder, pattern= &quot;*.jpg&quot;, full.names = TRUE) We identify cropping locations that remove the outer edges of the cage, and maintain a constant picture area across all iLAMs (e.g., 1800x1600 pixels) with the following command: load.image(file_names[1]) %&gt;% imsub(x %inr% c(x_left,x_right), y %inr% c(y_bot,y_top)) %&gt;% plot() Find all movements by image subtraction, global thresholding, and blob detection in the iLAM wrapper function find_movements(). -Additional optional settings: n_blr: Integer value to set blur radius to denoise image and reduce graininess, prior to image subtraction (default: n_blr = 3) n_grw: Integer value for n_cln multiplier to “grow” and aggregate blobs within a given proximity. For example, when n_cln=5 and n_grw = 1.5, blobs are first shrunk by 5 pixels and then grown by 5x1.5=7.5 pixels (default: n_grw = 1.5) n_max: Integer value denoting the maximum number of pixel differences expected between two images; any values above this n_max will be considered as noisy and assigned an arbitrary value for subsequent filtering/removal. See @ref(04-make_dam_output.Rmd) for more information. Example, if a moth movement = 3000 pixels and there are five moths in a cage, then the maximum number of differences expected is 15,000 pixels. (default: n_max = 75000) find_thr: Boolean value “T” (true) or “F” (false) to determine what pixel value cut-off corresponds to the n_thr percentile difference across a p_sample of image comparisons (default = “T”) type_thr: String value “absolute” or “relative” indicating whether to perform absolute (capture all differences &gt; n_thr for all pictures) or relative thresholding procedure (capture all differences &gt; n_thr for each comparison) on set of images. We recommend the default, “absolute” option because the latter identifies false movements in images where there are no movements because it always retains the top pixel differences. (default: find_thr = “absolute”) p_sample: Numeric value denoting the proportion of image comparisons that should be used to determine the absolute threshold value Note: If 5% of the total images is &lt;100, then increasing p_sample &gt;0.05 is recommended channel: String value denoting which color channel movements should be identified from (default: “grayscale”) out &lt;- find_movements(files = file_names, # list of file names n_thr = n_thr, # threshold value (0.992 == &quot;0.8%&quot;) n_cln = n_cln, # value for cleaning (number of pixels) n_grw = 1.5, # multiplier for n_cln (shrink vs. grow) n_blr = 3, # let user select blur radius n_max = 75000, # upper cut-off for # pixel differences x_left = x_left, # value for crop on x min x_right = x_right, # value for crop on x max y_bot = y_bot, # value for crop on y min y_top = y_top, # value for crop on y max find_thr = T, # T or F type_thr = &quot;absolute&quot;, p_sample = 0.05, # If 5% of the total images &lt; 100, then increase this value channel = &quot;grayscale&quot;, animal = animal) Update and save output containing all identified blobs, their size and location as a .csv in the current working directory. #adds additional columns to dataframe out$ID &lt;- paste0(n_thr*100,&quot;%_&quot;, &quot;s&quot;, n_cln, &quot;g&quot;, 1.5*n_cln) out$sex &lt;- sex out$genus &lt;- genus out$species &lt;- species if (file.exists(paste0(out_file_name,&quot;.csv&quot;))){ write.table(out, file = paste0(out_file_name,&quot;.csv&quot;), append = TRUE, quote = TRUE, sep = &quot;,&quot;, row.names = FALSE, col.names = FALSE) } else{ write.csv(out, file = paste0(out_file_name,&quot;.csv&quot;), col.names = TRUE, row.names = FALSE) } rm(out) Use plot_movements() to visualize movements by plotting detected blobs onto a subset of images. These images are helpful for tuning parameters. #circles in bottom left corner denote standards of sizes: 12800 px, 3200 px, 800 px, 200 px, 50 px plot_movements(file_names, pi_sub_folder, by_change, x_left, x_right, y_bot, y_top, n_max) Figure 4.2: iLAM plot_movements() image If desired, make a gif from plotted images with make_gif() library(magick) make_gif(out_file_name, pi_sub_folder) Figure 4.3: iLAM make_gif() output Tips: First test parameters settings for find_movements() with a subset of experimental images: e.g., find_movements(files = file_names[1:1000], p_sample=0.10) If find_movements() crashes, returns excess small blobs/movements, and/or returns excess blobs/movements that do NOT correspond to REAL movements, then increase the n_thr or p_sample values. If this issue continues, then remove any days at the experiment end where all/most insects have died; this can downwardly bias the average number of pixel differences expected across images. If find_movements() returns many small blobs/animal and you desire one blob/animal movement, then increase n_cln and/or n_grw "],["make-dam-output.html", "5 Make DAM Output", " 5 Make DAM Output Steps to convert iLAM output into Trikinetics DAM format for locomotor activity analyses Read in iLAM output from image_analysis and parse into a dataframe containing the size, centroid location, and origin (time, pi) of all identified blobs (by_change) with parse_movements() out_file_name = &quot;Pgreeni&quot; start_photophase = 5 #project-specific, time that lights turn on end_photophase = 21 #project-specific, time that dark starts #parse movements into workable dfs: all movements (by_change) and by_change_Pg &lt;- parse_movements(file_mvmnts = paste0(out_file_name,&quot;.csv&quot;), start_photophase = start_photophase, end_photophase = end_photophase) Table 5.1: iLAM by_change data frame …1 s x y pi time ID sex genus species treatment 1 2000000 0 0 mothra03 2022-06-24 21:00:00 99.9%_s10g15 male photinus greeni D 2 2799 1256 35 mothra03 2022-06-24 21:02:00 99.9%_s10g15 male photinus greeni D 3 2189 150 466 mothra03 2022-06-24 21:02:00 99.9%_s10g15 male photinus greeni D 4 731 1282 40 mothra03 2022-06-24 21:04:00 99.9%_s10g15 male photinus greeni D 5 442 1311 51 mothra03 2022-06-24 21:04:00 99.9%_s10g15 male photinus greeni D Collapse all identified blobs (within by_change_[]) into a dataframe containing the sum of blobs and number of blobs/movements observed per frame/timepoint (by_frame_[]) by_frame_Pg &lt;- by_change_Pg %&gt;% ungroup() %&gt;% group_by(pi, ID, time, treatment) %&gt;% dplyr::summarize(n = length(s[!is.na(s)]), #number of blobs of size (s) != NA s = sum(s, na.rm = TRUE)) %&gt;% #sum of blob sizes, NA removed dplyr::mutate(n = ifelse(s == 0, 0, n)) %&gt;% #if sum of blobs=0, then n&lt;-0 (otherwise it&#39;d be 1) distinct(pi, ID, time, treatment, n, s) #sanity check to remove any duplicates Filter movements captured from rare, noisy images. Noisy values were initially assigned an arbitrary value (2,000,000) by find_movements(). This step changes 2,000,000 with NA and then replaces with average value of the preceding and succeeding time points. These rare cases typically only occur at the image following a light-dark transition. For example, across a 7-day experiment (5040 images), only 0.4% image comparisons were assigned an arbitrary value. library(zoo) by_frame_Pg &lt;- by_frame_Pg %&gt;% ungroup() %&gt;% mutate(s = replace(s, s==2000000, NA), n = replace(n, is.na(s), NA)) by_frame_Pg &lt;- by_frame_Pg %&gt;% group_by(pi) %&gt;% mutate(s = round((na.locf0(s, fromLast = TRUE) + na.locf0(s, fromLast = FALSE))/2,0), n = round((na.locf0(n, fromLast = TRUE) + na.locf0(n, fromLast = FALSE))/2,0)) %&gt;% ungroup() by_frame_Pg &lt;- by_frame_Pg %&gt;% ungroup() %&gt;% mutate(s = replace(s, is.na(s), 0), n = replace(n, is.na(n), 0)) dplyr::filter(by_frame_Pg, n&gt;0) %&gt;% group_by(pi) %&gt;% dplyr::summarise(blob_size = mean((s/n), na.rm=TRUE)) #output the average blob size Table 5.2: iLAM by_frame data frame …1 pi ID time treatment n s 1 mothra01 99.9%_s10g15 2022-06-24 21:00:00 D 0 0 2 mothra01 99.9%_s10g15 2022-06-24 21:02:00 D 4 4084 3 mothra01 99.9%_s10g15 2022-06-24 21:04:00 D 2 2684 4 mothra01 99.9%_s10g15 2022-06-24 21:06:00 D 5 8803 5 mothra01 99.9%_s10g15 2022-06-24 21:08:00 D 9 18515 Use iLAM wrapper make_dam_file() to convert by_frame_[] into a DAM-like output and save as a DAM file with summed blob sizes/total movement (in pixels) per timepoint ilam_Pg = make_dam_file(by_frame_Pg, variable_name = &quot;s&quot;) #output a tab-delimited file containing write_tsv(ilam_Pg, &quot;ilam_Pg.tsv&quot;, col_names = F) write_tsv(ilam_Pg, &quot;Monitor42.txt&quot;, col_names = F) #some analysis programs require Monitor##.txt name Table 5.3: iLAM by_frame converted to DAM format X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 X11 X12 X13 X14 X15 X16 X17 X18 X19 X20 X21 X22 X23 X24 X25 X26 X27 X28 X29 X30 X31 X32 X33 X34 X35 X36 X37 X38 X39 X40 X41 X42 1 24 Jun 22 21:00:00 1 0 42 0 Ct 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 24 Jun 22 21:02:00 1 0 42 0 Ct 0 0 4084 1668 4988 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 24 Jun 22 21:04:00 1 0 42 0 Ct 0 0 2684 2981 3666 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 24 Jun 22 21:06:00 1 0 42 0 Ct 0 0 8803 22280 4058 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 24 Jun 22 21:08:00 1 0 42 0 Ct 0 0 18515 17325 5093 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 Use iLAM wrapper make_dam_file() to convert by_frame_[] into a DAM-like output and save as a DAM file with the number of blobs/movements per timepoint #parse movements into workable dfs: all movements (by_change) and by_change_Pg &lt;- parse_movements(file_mvmnts = paste0(out_file_name,&quot;.csv&quot;), start_photophase = start_photophase, end_photophase = end_photophase) by_frame_Pg = filter_nblobs(by_change_Pg) #filter out small nblobs using iLAM wrapper filter_nblobs() ilam_Pg = make_dam_file(by_frame_Pg, variable_name = &quot;n&quot;) write_tsv(ilam_Pg, &quot;ilam_Pg_n.tsv&quot;, col_names = F) write_tsv(ilam_Pg, &quot;Monitor43.txt&quot;, col_names = F) #some analysis programs require Monitor##.txt name Table 5.4: iLAM by_frame converted to DAM format X1 X2 X3 X4 X5 X6 X7 X8 X9 X10 X11 X12 X13 X14 X15 X16 X17 X18 X19 X20 X21 X22 X23 X24 X25 X26 X27 X28 X29 X30 X31 X32 X33 X34 X35 X36 X37 X38 X39 X40 X41 X42 1 24 Jun 22 21:00:00 1 0 42 0 Ct 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 2 24 Jun 22 21:02:00 1 0 42 0 Ct 0 0 2 0 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 3 24 Jun 22 21:04:00 1 0 42 0 Ct 0 0 2 1 2 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 4 24 Jun 22 21:06:00 1 0 42 0 Ct 0 0 5 3 3 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 5 24 Jun 22 21:08:00 1 0 42 0 Ct 0 0 8 6 4 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 "],["analyze-movement-data.html", "6 Analyze Movement Data", " 6 Analyze Movement Data In our research, we utilize the Rethomics framework for data analysis. A more detailed walk-through can be found in the original Rethomics publication and online tutorial. Some example transformations and visualizations of iLAM/DAM2 data are presented below: Read in metadata for experiment metadata_o = read_delim(&quot;metadata_onub.csv&quot;, delim = &quot;;&quot;, escape_double = FALSE, trim_ws = TRUE) Table 6.1: iLAM metadata example file start_datetime stop_datetime swap_datetime region_id species pi sex strain iLAM_BE_mf.txt 2022-08-10 03:00:00 2022-08-18 02:58:00 2022-08-13 03:00:00 1 O_nubilalis mothra01 male be iLAM_BE_mf.txt 2022-08-10 03:00:00 2022-08-18 02:58:00 2022-08-13 03:00:00 2 O_nubilalis mothra02 female be iLAM_BE_mf.txt 2022-08-10 03:00:00 2022-08-18 02:58:00 2022-08-13 03:00:00 3 O_nubilalis mothra03 female be iLAM_BE_mf.txt 2022-08-10 03:00:00 2022-08-18 02:58:00 2022-08-13 03:00:00 4 O_nubilalis plantcam01 female be iLAM_BE_mf.txt 2022-08-10 03:00:00 2022-08-18 02:58:00 2022-08-13 03:00:00 5 O_nubilalis plantcam02 male be iLAM_BE_mf.txt 2022-08-10 03:00:00 2022-08-18 02:58:00 2022-08-13 03:00:00 6 O_nubilalis plantcam03 male be Link metadata with the iLAM files metadata_o = metadata_o %&gt;% link_dam_metadata(result_dir = getwd()) iLAM_onub &lt;- load_dam(metadata_o) summary(iLAM_onub) Split data by identifiers iLAM_BE = iLAM_onub[xmv(strain) == &quot;be&quot;] Add unique identifier (uid) for specific identification for each cage/experiment/species iLAM_BE[, uid := 1:.N, meta=T] For each timepoint, collapse rows/observations into 30 minute bins The sum of every 15 rows; 15 = seq(0,14) = 30min bins iLAM_BE[, activity_bin := rollapply(activity, list(seq(0, 14)), FUN=function(x) sum(x, na.rm=TRUE), partial = TRUE, fill = NA), by = xmv(uid)] For each uid, retain only the 15th row (t) = 30min bins iLAM_BE = iLAM_BE[, .SD[seq(1, .N, 15)], by = id] Calculate average activity across all bins to normalize activity_bins between cages iLAM_BE[, uid := 1:.N, meta=T] iLAM_BE[, fctr := .(10/mean(activity_bin)), by = xmv(uid)] iLAM_BE[, .N, by=xmv(uid)] #verify that proper number of bins were kept iLAM_BE[, .(mean_acti = 1/mean(activity_bin)), by=xmv(uid)] Multiple activity_bin by normalization factor iLAM_BE[, acn := activity_bin*fctr] Visualize average across individuals for first 72 hours p_be_activity = ggetho(iLAM_BE, aes(y=acn, colour=sex), time_wrap = hours(25)) + stat_pop_etho(size=0.75) + stat_ld_annotations(l_duration = as.numeric(hours(16)), ld_colours = c(&quot;#FDFD66&quot;,&quot;black&quot;)) + stat_ld_annotations(x_limits = days(c(3,7)), ld_colours = c(&quot;grey&quot;, &quot;black&quot;)) + theme_bw() + theme(text = element_text(size = 12, family = &quot;sans&quot;, color = &#39;black&#39;), panel.grid.major = element_blank(), panel.grid.minor = element_blank(), legend.position = c(0.12,0.7), legend.text = element_text(size=10, face = &quot;italic&quot;), legend.title = element_blank()) + ylab(&quot;Activity&quot;) + xlab(&quot;Time (ZT)&quot;) + scale_color_manual(values = c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;), labels = c(paste(&quot;O. nubilalis&quot;, &quot;\\u2640&quot;), paste(&quot;O. nubilalis&quot;, &quot;\\u2642&quot;))) + scale_fill_manual(values = c(&quot;#E69F00&quot;, &quot;#56B4E9&quot;), labels = c(paste(&quot;O. nubilalis&quot;, &quot;\\u2640&quot;), paste(&quot;O. nubilalis&quot;, &quot;\\u2642&quot;))) + ylim(c(0,60)) Figure 6.1: Activity of European corn borer moths in LD. Activity was captured by iLAM across three days of LD (A). Phase of peak activity (B) and percent activity that occured at night (C). Tips: There are many other useful R packages that can be leveraged to analyze locomotor activity data in the DAM2 format. Some examples are: Rtivity publication and online shiny app RhythmicAlly publication and online repository VANESSA publication and online repository "],["sample-work-flow.html", "7 Sample Work-Flow", " 7 Sample Work-Flow 1. Rear and/or collect experimental insects 2. Set up experiment room: Arrange lighting Schedule light timers Arrange iLAM flight cages 3. Furnish iLAMs: Fill water and/or food containers Add to base or ceiling of flight cages 4. Program iLAMs Modify crontab file Delete old images to free storage on Pi’s SD card Verify that Pi and PC (that photos are uploaded to) contain sufficient storage for the experiment’s duration Verify that camera is connected, centered, and focused If images are automatically uploaded, verify that Pis are connected to Wifi and synced to upload directory 5. Load insects: Add insects (5-10/cage) Write and save a README.txt file with experiment information into directory that images are uploaded into 6. Start experiment 7. Check-in: Verify images uploaded Verify that light transitions occurred at expected times Verify that SD card contains appropriate storage space for the experiment’s duration 8. End experiment 9. Store data: Sometimes, Wifi interruptions can prevent successful image upload. Verify that no images are missing from any Pis Directly download any outstanding images from Pis Save images in directory for analysis 10. Identify movements by post-process image segmentation 11. Analyze and plot movement data from experiment Tips: On average, a .jpg image captured by an iLAM requires 2.3-3.0 MB storage. If images are captured every 2 min x 7 days, then est. 11.6-15.1 GB storage required/iLAM "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
